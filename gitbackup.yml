---
- hosts: localhost
  become: yes
  vars:
    bucket: kmss3check
    git_repo_url: "https://github.com/gody48/PageObjectModel.git"
    latestfiles: false
    gitrepo: true
  tasks:
#  - name: Uploading the files to s3
#    shell: |
#      git config --global credential.helper cache
#      git clone https://github.com/gody48/ansible-backup-s3.git && cd ansible-backup-s3
#      git log --pretty=format: --name-only --since="2 days ago" --until="1 seconds ago" | sort | uniq | awk 'NF'
#      for file in `git log --pretty=format: --name-only --since="2 days ago" --until="1 seconds ago" | sort | uniq | awk 'NF'`
#      do
#         aws s3 cp $file s3://kmss3check/$file
#      done
#      rm -rf /tmp/ansible-backup-s3
#    args:
#      chdir: /tmp/
#    register: filelist

  - name: Filtering out repo name
    set_fact:
      git_repo_name: "{{ git_repo_url | regex_search('[^//]+$') | regex_replace('.git', '') }}"

  - name: Uploading all files from {{git_repo_name}} github repo to {{bucket}} s3 bucket
    shell: |
      git config --global credential.helper cache
      git clone {{git_repo_url}} 
      aws s3 cp {{git_repo_name}} s3://{{bucket}}/{{git_repo_name}} --exclude ".git/*" --recursive
      cd {{git_repo_name}} && git log --pretty="The author of %h was %an, %ar%nCommit message: %s%n" > {{git_repo_name}}_commit_log.txt
      aws s3 cp {{git_repo_name}}_commit_log.txt s3://{{bucket}}/{{git_repo_name}}/{{git_repo_name}}_commit_log.txt
    args:
      chdir: /tmp
    when: gitrepo
 
  - name: Uploading the latest updated or created files from {{git_repo_name}} github repo to {{bucket}} s3 bucket, since a day
    shell: |
      git config --global credential.helper cache
      git clone {{git_repo_url}} && cd {{git_repo_name}}
      for filepush in `git log --pretty=format: --name-only --since="1 days ago" --until="1 seconds ago" | sort | uniq | awk 'NF'`
      do
         aws s3 cp $filepush s3://{{bucket}}/$filepush
         git log --pretty="The author of %h was %an, %ar%nCommit message: %s%n" > {{git_repo_name}}_commit_log.txt
         aws s3 cp {{git_repo_name}}_commit_log.txt s3://{{bucket}}/{{git_repo_name}}/{{git_repo_name}}_commit_log.txt
      done
    when: latestfiles
  
#for filedelete in `git log --name-only --since="2 days ago" --until="1 seconds ago" | sort | uniq | awk 'NF' | grep "    Delete " | awk '{print $2}'`
#do
#    aws s3api delete-object --bucket {{bucket}} --key $filedelete
#done

